{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4N5sPQj7UNZY3x+H1U+06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatlesatani/coding_september/blob/main/sentiment_analysis_with_pretrained_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook contains codes that do sentiment_analysis using transformer library which is like words-embedding, pre-trained classification model. However, I tried to make classification model without  pre-trained model. As a result, my machine power was not enough to make iteration. So, I switched to use pre-trained model from transformer.\n",
        "\n",
        "### the codes in this notebook is based on https://github.com/curiousily/Getting-Things-Done-with-Pytorch/blob/master/09.deploy-BERT-with-FastAPI.ipynb"
      ],
      "metadata": {
        "id": "1auHFTD4tsv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pFIXfxaStstK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_aYKOTq9tsp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ax9DUZT_tsjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wz_XM14Otsbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF7ORJBPqC4k",
        "outputId": "18388475-7261-4d9f-c397-c40912037855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.14.0)\n",
            "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow_text) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow_text) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " pip install \"tf-models-official==2.13.*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6AOkMG8qDyD",
        "outputId": "eb0d6e9b-9623-4377-b8ea-9e8b25ca9a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf-models-official==2.13.* in /usr/local/lib/python3.10/dist-packages (2.13.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.84.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.0.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.5.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.23.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.8.0.76)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (6.0.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.11.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.1.99)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.14.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (0.7.5)\n",
            "Requirement already satisfied: tensorflow-text~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.13.*) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.13.*) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.13.*) (6.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official==2.13.*) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official==2.13.*) (0.33.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.13.*) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official==2.13.*) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.13.*) (4.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official==2.13.*) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.13.*) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.4.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.13.*) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.41.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (6.0.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official==2.13.*) (3.16.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official==2.13.*) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official==2.13.*) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.13.*) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (2.3.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.13.*) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.13.*) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official==2.13.*) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZR29T-dzX8P",
        "outputId": "d6fc438f-02f1-481b-c66a-5103aca8f06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn, optim\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "jyUTK23gqO4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setup the dataset\n",
        "test = 'https://raw.githubusercontent.com/beatlesatani/coding_september/main/test.csv'\n",
        "train = \"https://raw.githubusercontent.com/beatlesatani/coding_september/main/train.csv\"\n",
        "test = pd.read_csv(test,encoding='unicode_escape')\n",
        "train = pd.read_csv(train,encoding='unicode_escape')\n",
        "# remove unusuful columns\n",
        "test = test.iloc[:,1:3]\n",
        "train = train.iloc[:, [1,3]]\n",
        "#check the insull values of train dataframe\n",
        "train.isnull().sum()\n",
        "#only one text is missing, so drop that low that incluse null cell\n",
        "train = train.dropna()\n",
        "#re-check null values\n",
        "train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw84-iNMqHRb",
        "outputId": "38ca8878-2f1c-40a9-ffae-d5a629d33f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the insull values of train dataframe\n",
        "test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y83pTupqMoj",
        "outputId": "0b48b8a7-e9a5-4c82-984e-9cbd70db908d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         1281\n",
              "sentiment    1281\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#afeter checking original csv file, all raws after 3533 is null\n",
        "test = test.dropna()\n",
        "#re-check null values\n",
        "test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEAnxZhUqvde",
        "outputId": "17b8d011-d6d1-49ed-8212-c9caca440942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the label imbalance\n",
        "train['sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkUVTa8xrd2V",
        "outputId": "b1a6fe5d-894d-4bc9-ccab-b22f9166cc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     0.404549\n",
              "positive    0.312300\n",
              "negative    0.283151\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYZ-pNcQrhge",
        "outputId": "0703a5ad-f5da-478e-fcc2-1c57fef66166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     0.404641\n",
              "positive    0.312111\n",
              "negative    0.283248\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#graph\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.countplot(x='sentiment', data=train, ax=axes[0],saturation = 0.75)\n",
        "axes[0].set_title('Train Data')\n",
        "\n",
        "# Plot the countplot for 'sentiment' in the 'test' DataFrame\n",
        "sns.countplot(x='sentiment', data=test, ax=axes[1])\n",
        "axes[1].set_title('Test Data')\n",
        "\n",
        "# Adjust layout for better visibility\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "ZrppB8JQrkW9",
        "outputId": "f63e1ebf-157a-4293-df59-c00d91be60da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## we can conclude the labels are not inbalanced"
      ],
      "metadata": {
        "id": "UwqjoQTrrtVC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G343Ows7CGNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## convert each sentiment into numerical value\n",
        "neagtive → -1\n",
        "neutral → 0\n",
        "postive → 1"
      ],
      "metadata": {
        "id": "_MwZkaTErtu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#before working to the model, convert labels into numerical number\n",
        "train['label'] = train['sentiment'].apply(lambda x: -1 if x== 'negative' else(0 if x == 'neutral' else 1))\n",
        "train = train.drop('sentiment',axis = 1)\n",
        "test['label'] = test['sentiment'].apply(lambda x: -1 if x== 'negative' else(0 if x == 'neutral' else 1))\n",
        "test = test.drop('sentiment',axis = 1)\n",
        "'''\n",
        "# Convert labels to integers: negative -> 0, neutral -> 1, positive -> 2\n",
        "train['label'] = train['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n",
        "test['label'] = test['sentiment'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n"
      ],
      "metadata": {
        "id": "oPTaiiAcrn6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train['label'].value_counts(normalize=True) # got same ratio before converting"
      ],
      "metadata": {
        "id": "5IBlifFWr4t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "split the dataset\n",
        "X_train = train['text']\n",
        "y_train = train['label']\n",
        "X_test = test['text']\n",
        "y_test = test['label']\n",
        "'''"
      ],
      "metadata": {
        "id": "n82UTz4Xr7UI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3509659b-60dc-4f57-d69e-c0a6755b0977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nsplit the dataset\\nX_train = train['text']\\ny_train = train['label']\\nX_test = test['text']\\ny_test = test['label']\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#convert label to one-hot-coding\n",
        "y_train = pd.get_dummies(y_train, columns = ['label'])\n",
        "y_test = pd.get_dummies(y_test, columns = ['label'])\n",
        "'''"
      ],
      "metadata": {
        "id": "ZZcqQIT7r-74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "892ce892-89d6-406d-bcc5-035128121d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#convert label to one-hot-coding\\ny_train = pd.get_dummies(y_train, columns = ['label'])\\ny_test = pd.get_dummies(y_test, columns = ['label'])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From here I will use transformer library from Hugging-face.\n",
        "The transformer library of Hugging Face contains PyTorch implementation of state-of-the-art NLP models including BERT (from Google), GPT (from OpenAI) ... and pre-trained model weights."
      ],
      "metadata": {
        "id": "IQ7V2F3AsbLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "metadata": {
        "id": "W14Yj7x_00Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "3sRgoDj41Pze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokens = tokenizer.tokenize(train.iloc[0,0])\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Sentence: {train.iloc[0,0]}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XPDgMEX1a9S",
        "outputId": "8ec96930-9ea7-413e-b7f8-ecf95bf186a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sentence:  I`d have responded, if I were going\n",
            "   Tokens: ['I', '`', 'd', 'have', 'responded', ',', 'if', 'I', 'were', 'going']\n",
            "Token IDs: [146, 169, 173, 1138, 5133, 117, 1191, 146, 1127, 1280]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6U5YbpluC18N",
        "outputId": "0f26481d-8a9f-47ed-8537-9e9e6c261592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text sentiment  label\n",
              "0                    I`d have responded, if I were going   neutral      1\n",
              "1          Sooo SAD I will miss you here in San Diego!!!  negative      0\n",
              "2                              my boss is bullying me...  negative      0\n",
              "3                         what interview! leave me alone  negative      0\n",
              "4       Sons of ****, why couldn`t they put them on t...  negative      0\n",
              "...                                                  ...       ...    ...\n",
              "27476   wish we could come see u on Denver  husband l...  negative      0\n",
              "27477   I`ve wondered about rake to.  The client has ...  negative      0\n",
              "27478   Yay good for both of you. Enjoy the break - y...  positive      2\n",
              "27479                         But it was worth it  ****.  positive      2\n",
              "27480     All this flirting going on - The ATG smiles...   neutral      1\n",
              "\n",
              "[27480 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aaf77c19-2a74-45e9-8456-26ef7ca9aec5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27476</th>\n",
              "      <td>wish we could come see u on Denver  husband l...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27477</th>\n",
              "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27478</th>\n",
              "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27479</th>\n",
              "      <td>But it was worth it  ****.</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27480</th>\n",
              "      <td>All this flirting going on - The ATG smiles...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27480 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aaf77c19-2a74-45e9-8456-26ef7ca9aec5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aaf77c19-2a74-45e9-8456-26ef7ca9aec5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aaf77c19-2a74-45e9-8456-26ef7ca9aec5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46243f2b-bc43-4417-989b-6adf521691e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46243f2b-bc43-4417-989b-6adf521691e4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46243f2b-bc43-4417-989b-6adf521691e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.sep_token, tokenizer.sep_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAFmKn-H1a-z",
        "outputId": "e2e84c88-2afb-4aed-eda0-ce20658974b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', 102)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.cls_token, tokenizer.cls_token_id\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f2WIU2B1bBA",
        "outputId": "8a987664-85db-458f-9428-43877374b470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', 101)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer.pad_token, tokenizer.pad_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQV_FYGm1bL0",
        "outputId": "27cc56f9-f2b5-486f-90e1-7cf58b7e8e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.unk_token, tokenizer.unk_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb7azX-g1bRa",
        "outputId": "69c1abed-6516-4f73-9ecb-883397544159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[UNK]', 100)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOxbwtjOOpRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_encode = train.iloc[25][0]\n",
        "print(text_to_encode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVcI7QdTOeDt",
        "outputId": "63ece659-cede-482e-bbef-3f6c41bb96a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the free fillin` app on my ipod is fun, im addicted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  text_to_encode,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  padding=\"max_length\",\n",
        "  #truncation = True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "\n",
        "encoding.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49ISDmXb1bUm",
        "outputId": "72df84c0-5e65-4099-bbc3-b04a4f353331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1VzIDVX1bWq",
        "outputId": "162b4787-9f87-4ac3-daf5-14962bea0985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  1103,  1714,  5475,  1394,   169, 12647,  1113,  1139,   178,\n",
              "         5674,  1181,  1110,  4106,   117, 13280,  5194, 27825,   102,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding['attention_mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jPq-zZ5P67H",
        "outputId": "999aebef-e7ad-4562-a89f-391fe0e214cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsShWSg41biK",
        "outputId": "f778a552-87db-4208-da78-0074d758cddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'the',\n",
              " 'free',\n",
              " 'fill',\n",
              " '##in',\n",
              " '`',\n",
              " 'app',\n",
              " 'on',\n",
              " 'my',\n",
              " 'i',\n",
              " '##po',\n",
              " '##d',\n",
              " 'is',\n",
              " 'fun',\n",
              " ',',\n",
              " 'im',\n",
              " 'add',\n",
              " '##icted',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to find the longest length, I gonna concat train,test\n",
        "df = pd.concat([train,test])"
      ],
      "metadata": {
        "id": "wQMYe44z3BsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df[\"text\"]:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57z_7GZS1bn2",
        "outputId": "798fa8fa-bfd3-4d6c-9d5b-0fdbd3da4ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "vSgvuOtR1bx3",
        "outputId": "2597ebc1-feed-4c64-8ae2-2599f47a7229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-89-4dbe9bd8b56e>:1: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(token_lens)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I chose 75\n",
        "MAX_LEN = 75\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "qd8rmZNm1b5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, text, label, tokenizer, max_len):\n",
        "    self.text = text\n",
        "    self.label = label\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    text = str(self.text[item])\n",
        "    label = self.label[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      text,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'text': text,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'label': torch.tensor(label, dtype=torch.long)\n",
        "    }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7dCY0cH51b8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ここはtrain,testのままでいけると判断  df_valのみを作る\n",
        "train, df_value = train_test_split(train, test_size=0.1, random_state=101)"
      ],
      "metadata": {
        "id": "Q1GndJs2GF48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape,test.shape,df_value.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21-vpCxsGu_J",
        "outputId": "cfbafb11-4422-49b4-feab-eb1310b52a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24732, 3), (3534, 3), (2748, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    text=df.text.to_numpy(),\n",
        "    label=df.label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "AAngjmBN1b9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_value, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0jwlZRi5lTy",
        "outputId": "e727b6a1-c01f-4ffb-97e0-6b0a6ee34583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "132C2AWU1b_g",
        "outputId": "f30ad84f-539d-4e0b-9577-3fdbf2602668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['text', 'input_ids', 'attention_mask', 'label'])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['label'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGtSjBFq1cA3",
        "outputId": "c44fbda3-87a7-4a75-ac42-bed5df828333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 75])\n",
            "torch.Size([16, 75])\n",
            "torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "-OuV_55e1cCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'],\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "metadata": {
        "id": "4pYiovTk1cEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#last_hidden_state.shape"
      ],
      "metadata": {
        "id": "Yv1JzQ-iIL19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model.config.hidden_size"
      ],
      "metadata": {
        "id": "H0TmtFqyIMNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80106d86-843a-44ef-bd03-966cf43033ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pooled_output.shape"
      ],
      "metadata": {
        "id": "dnieRFJRIMfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(bert_model.config.hidden_size, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        pooled_output = bert_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )[1]  # Take the pooled_output from BERT\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)\n"
      ],
      "metadata": {
        "id": "KLee6yUUGLpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = SentimentClassifier(len(label_mapping))"
      ],
      "metadata": {
        "id": "HgN7XdJBGPhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer for the classifier\n",
        "classifier_loss_fn = nn.CrossEntropyLoss()\n",
        "classifier_optimizer = optim.AdamW(classifier_model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "PWt1KgT-GVbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the classifier\n",
        "def train_classifier_epoch(\n",
        "    model,\n",
        "    data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    n_examples\n",
        "):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"label\"]\n",
        "\n",
        "        classifier_optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "        train_loss = loss_fn(outputs, labels)\n",
        "\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        losses.append(train_loss.item())\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "QOvEYyrZGmTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['negative', 'neutral', 'positive']\n",
        "model = SentimentClassifier(len(class_names))"
      ],
      "metadata": {
        "id": "Zk3ZpPRMIMjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation loop for the classifier\n",
        "def eval_classifier_model(model, data_loader, loss_fn, n_examples):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch[\"input_ids\"]\n",
        "            attention_mask = batch[\"attention_mask\"]\n",
        "            labels = batch[\"label\"]\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            val_loss = loss_fn(outputs, labels)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(val_loss.item())\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n",
        "# Number of training epochs for the classifier\n",
        "CLASSIFIER_EPOCHS = 5"
      ],
      "metadata": {
        "id": "ywDVu2MRIMmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for the classifier\n",
        "for epoch in range(CLASSIFIER_EPOCHS):\n",
        "    print(f'Classifier Epoch {epoch + 1}/{CLASSIFIER_EPOCHS}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_acc, train_loss = train_classifier_epoch(\n",
        "        classifier_model,\n",
        "        train_data_loader,\n",
        "        classifier_loss_fn,\n",
        "        classifier_optimizer,\n",
        "        len(train_data)\n",
        "    )\n"
      ],
      "metadata": {
        "id": "qPXNBRaWGkzO",
        "outputId": "83ff42d9-4731-408a-9286-e1d4c733fd4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier Epoch 1/5\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-06bb44890716>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     train_acc, train_loss = train_classifier_epoch(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-127-4bd4b31353dd>\u001b[0m in \u001b[0;36mtrain_classifier_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, n_examples)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mclassifier_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-124-0923139e152d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         pooled_output = bert_model(\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         )\n\u001b[0;32m-> 1022\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1023\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    610\u001b[0m                 )\n\u001b[1;32m    611\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    613\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    498\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 427\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kx2Azk5LGlao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "M3dsphucRnUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "    model,\n",
        "    data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    n_examples\n",
        "):\n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for d in data_loader:\n",
        "        input_ids = d[\"input_ids\"]\n",
        "        attention_mask = d[\"attention_mask\"]\n",
        "        label = d[\"label\"]\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs, label)\n",
        "\n",
        "        correct_predictions += torch.sum(preds == label)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "zLU5Kd7wIMpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader, loss_fn, n_examples):\n",
        "    model.eval()\n",
        "\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"]\n",
        "            attention_mask = d[\"attention_mask\"]\n",
        "            labels = d[\"label\"]  # Assuming labels are already integers\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "metadata": {
        "id": "3jPf9M1cIMrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        train_data_loader,\n",
        "        loss_fn,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        len(train)\n",
        "    )\n",
        "\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_data_loader,\n",
        "        loss_fn,\n",
        "        len(df_value)\n",
        "    )\n",
        "\n",
        "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    # Get predictions on the validation data\n",
        "    val_predictions = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in val_data_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            predictions = torch.argmax(outputs, dim=1)\n",
        "            val_predictions.extend(predictions.cpu().numpy())\n",
        "\n",
        "    print(\"Val Labels:\", [label.item() for label in df_value[\"label\"]])\n",
        "    print(\"Val Predictions:\", val_predictions)\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "        best_accuracy = val_acc\n"
      ],
      "metadata": {
        "id": "D0vmYuhMIMtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AGB3Yj01IMu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYT32IobIMwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWAm1vQTINHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mlN9pkmjINjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8f4eS5IIINn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcMJ2eikINps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lUiYKUfSINs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nywBYz5INyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMkXSZewINz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyJzcpZpIN2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hEjFtIWFIN4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uzT-8zkrIN5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRRVcRDjIN6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IN8fTqJfIN7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OARMtp1IN8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "20r_EF-SIOAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BSzY5ZyIOF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlSjRR7TIOHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vw5Na2JGIOI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dz9WT6MxIORH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vfi4_nUrDXiQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}